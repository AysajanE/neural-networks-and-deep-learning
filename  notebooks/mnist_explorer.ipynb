{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a9a252-f4ca-4193-9c44-f95ba0001506",
   "metadata": {},
   "source": [
    "# MNIST Image Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a12395-3c29-4e4f-a8bd-187edfa3d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mnist_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4a086-adfc-4131-9ce7-21a81f7c43bd",
   "metadata": {},
   "source": [
    "## MNIST Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9beee3c6-b689-4339-b3eb-83e59c735383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mnist_example(index=0):\n",
    "    \"\"\"\n",
    "    Load MNIST data, select a specific example, and visualize it.\n",
    "    \n",
    "    Args:\n",
    "    index (int): Index of the example to visualize (default is 0)\n",
    "    \"\"\"\n",
    "    # Load the MNIST data\n",
    "    training_data, validation_data, test_data = mnist_loader.load_data()\n",
    "    \n",
    "    # Select a specific example\n",
    "    X, y = training_data[0][index], training_data[1][index]\n",
    "    \n",
    "    # Reshape the flattened image back to 28x28\n",
    "    image = X.reshape(28, 28)\n",
    "    \n",
    "    # Print the label\n",
    "    print(f\"Label (digit): {y}\")\n",
    "    \n",
    "    # Print the pixel values\n",
    "    print(\"\\nPixel values (28x28 matrix):\")\n",
    "    print(image)\n",
    "    \n",
    "    # Visualize the image\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"MNIST Image: Digit {y}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics about the image\n",
    "    print(f\"\\nImage statistics:\")\n",
    "    print(f\"Minimum pixel value: {image.min()}\")\n",
    "    print(f\"Maximum pixel value: {image.max()}\")\n",
    "    print(f\"Mean pixel value: {image.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0076bb9-7968-4d71-804c-65607763fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label (digit): 9\n",
      "\n",
      "Pixel values (28x28 matrix):\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0703125  0.41015625 0.88671875 0.98828125 0.98828125\n",
      "  0.4765625  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22265625 0.77734375 0.98828125 0.984375   0.984375   0.984375\n",
      "  0.984375   0.62109375 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.078125\n",
      "  0.82421875 0.984375   0.90625    0.59375    0.28515625 0.65234375\n",
      "  0.984375   0.83984375 0.0234375  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.76953125\n",
      "  0.984375   0.7109375  0.         0.         0.         0.14453125\n",
      "  0.91796875 0.94921875 0.18359375 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.734375\n",
      "  0.984375   0.40234375 0.         0.         0.         0.14453125\n",
      "  0.91796875 0.89453125 0.10546875 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.73828125\n",
      "  0.98828125 0.3359375  0.03125    0.16796875 0.54296875 0.7421875\n",
      "  0.82421875 0.17578125 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.90625\n",
      "  0.984375   0.78125    0.78515625 0.984375   0.984375   0.328125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.83203125\n",
      "  0.95703125 0.984375   0.98828125 0.984375   0.9453125  0.1640625\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21875    0.328125   0.98828125 0.984375   0.625      0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17578125 0.98828125 0.984375   0.1484375  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.34765625 0.99609375 0.98828125 0.1484375  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3125     0.98828125 0.73828125 0.125      0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16015625 0.69921875 0.90625    0.328125   0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05859375\n",
      "  0.87890625 0.984375   0.44921875 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.59765625\n",
      "  0.984375   0.640625   0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.265625   0.95703125\n",
      "  0.94921875 0.30859375 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.125      0.92578125 0.95703125\n",
      "  0.3203125  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.03515625 0.578125   0.984375   0.66015625\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4140625  0.98828125 0.765625   0.02734375\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2109375  0.890625   0.50390625 0.109375   0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image statistics:\n",
      "Minimum pixel value: 0.0\n",
      "Maximum pixel value: 0.99609375\n",
      "Mean pixel value: 0.09\n"
     ]
    }
   ],
   "source": [
    "# Visualize the first example in the training set\n",
    "visualize_mnist_example(19)\n",
    "\n",
    "# You can change the index to view different examples\n",
    "# For example, uncomment the next line to see the 100th example:\n",
    "# visualize_mnist_example(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dad51b8-1fe5-48e1-b104-bb85ce066309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_mnist_data():\n",
    "    \"\"\"\n",
    "    Explore and compare the raw MNIST data with the wrapped version.\n",
    "    \"\"\"\n",
    "    # Load raw data\n",
    "    raw_training_data, raw_validation_data, raw_test_data = mnist_loader.load_data()\n",
    "    \n",
    "    # Load wrapped data\n",
    "    wrapped_training_data, wrapped_validation_data, wrapped_test_data = mnist_loader.load_data_wrapper()\n",
    "    \n",
    "    print(\"Raw Data Structure:\")\n",
    "    print(f\"Training data shape: {raw_training_data[0].shape}, {raw_training_data[1].shape}\")\n",
    "    print(f\"Validation data shape: {raw_validation_data[0].shape}, {raw_validation_data[1].shape}\")\n",
    "    print(f\"Test data shape: {raw_test_data[0].shape}, {raw_test_data[1].shape}\")\n",
    "    \n",
    "    print(\"\\nWrapped Data Structure:\")\n",
    "    print(f\"Training data: {len(wrapped_training_data)} examples\")\n",
    "    print(f\"Validation data: {len(wrapped_validation_data)} examples\")\n",
    "    print(f\"Test data: {len(wrapped_test_data)} examples\")\n",
    "    \n",
    "    # Examine a single example from each dataset\n",
    "    print(\"\\nExamining a single example from each dataset:\")\n",
    "    \n",
    "    # Raw training data\n",
    "    print(\"\\nRaw training data:\")\n",
    "    print(f\"Input shape: {raw_training_data[0][0].shape}\")\n",
    "    print(f\"Label: {raw_training_data[1][0]}\")\n",
    "    \n",
    "    # Wrapped training data\n",
    "    print(\"\\nWrapped training data:\")\n",
    "    print(f\"Input shape: {wrapped_training_data[0][0].shape}\")\n",
    "    print(f\"Label shape: {wrapped_training_data[0][1].shape}\")\n",
    "    \n",
    "    # Raw validation data\n",
    "    print(\"\\nRaw validation data:\")\n",
    "    print(f\"Input shape: {raw_validation_data[0][0].shape}\")\n",
    "    print(f\"Label: {raw_validation_data[1][0]}\")\n",
    "    \n",
    "    # Wrapped validation data\n",
    "    print(\"\\nWrapped validation data:\")\n",
    "    print(f\"Input shape: {wrapped_validation_data[0][0].shape}\")\n",
    "    print(f\"Label: {wrapped_validation_data[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f892c925-097b-468a-9ed8-5df5183c60b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data Structure:\n",
      "Training data shape: (50000, 784), (50000,)\n",
      "Validation data shape: (10000, 784), (10000,)\n",
      "Test data shape: (10000, 784), (10000,)\n",
      "\n",
      "Wrapped Data Structure:\n",
      "Training data: 50000 examples\n",
      "Validation data: 10000 examples\n",
      "Test data: 10000 examples\n",
      "\n",
      "Examining a single example from each dataset:\n",
      "\n",
      "Raw training data:\n",
      "Input shape: (784,)\n",
      "Label: 5\n",
      "\n",
      "Wrapped training data:\n",
      "Input shape: (784, 1)\n",
      "Label shape: (10, 1)\n",
      "\n",
      "Raw validation data:\n",
      "Input shape: (784,)\n",
      "Label: 3\n",
      "\n",
      "Wrapped validation data:\n",
      "Input shape: (784, 1)\n",
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Run the exploration\n",
    "explore_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5e8d5-0786-480d-aaab-f64b62c7dc8a",
   "metadata": {},
   "source": [
    "## Why we need `load_data_wrapper` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b300f6-37f4-491b-92a5-702bbbe9fba0",
   "metadata": {},
   "source": [
    "Let's explore the data produced by the `load_data_wrapper` function and compare it to the data from the `load_data` function. This will help us understand why the wrapper is useful for neural network training.\n",
    "\n",
    "Now, let's go through this code and explain the differences between the raw data and the wrapped data:\n",
    "\n",
    "1. We first load both the raw data (using `load_data`) and the wrapped data (using `load_data_wrapper`).\n",
    "\n",
    "2. We print the structure of both datasets.\n",
    "\n",
    "3. We examine a single example from each dataset to see the differences in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c2c60-a545-47fb-8435-9b0dd2bdddac",
   "metadata": {},
   "source": [
    "When we run this code, we'll see output similar to the following:\n",
    "\n",
    "```\n",
    "Raw Data Structure:\n",
    "Training data shape: (50000, 784), (50000,)\n",
    "Validation data shape: (10000, 784), (10000,)\n",
    "Test data shape: (10000, 784), (10000,)\n",
    "\n",
    "Wrapped Data Structure:\n",
    "Training data: 50000 examples\n",
    "Validation data: 10000 examples\n",
    "Test data: 10000 examples\n",
    "\n",
    "Examining a single example from each dataset:\n",
    "\n",
    "Raw training data:\n",
    "Input shape: (784,)\n",
    "Label: 5\n",
    "\n",
    "Wrapped training data:\n",
    "Input shape: (784, 1)\n",
    "Label shape: (10, 1)\n",
    "\n",
    "Raw validation data:\n",
    "Input shape: (784,)\n",
    "Label: 4\n",
    "\n",
    "Wrapped validation data:\n",
    "Input shape: (784, 1)\n",
    "Label: 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bbc4d-05dd-4955-bb29-c4fd7a6bc231",
   "metadata": {},
   "source": [
    "Now, let's discuss why we need the wrapper and the differences between the raw and wrapped data:\n",
    "\n",
    "1. Input Shape:\n",
    "   - Raw data: The input is a 1D array with shape (784,)\n",
    "   - Wrapped data: The input is a 2D array with shape (784, 1)\n",
    "   \n",
    "   Reason: The (784, 1) shape is more suitable for matrix operations in neural networks. It represents a column vector, which is typically how we represent input in neural network computations.\n",
    "\n",
    "2. Label Representation (Training Data):\n",
    "   - Raw data: The label is a single integer (e.g., 5)\n",
    "   - Wrapped data: The label is a 10-dimensional vector (e.g., [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] for digit 5)\n",
    "   \n",
    "   Reason: This is called \"one-hot encoding\". It's useful for neural network training because:\n",
    "     a) It allows the network to output probabilities for each digit.\n",
    "     b) It makes it easier to compute the error of the network's output.\n",
    "     c) It's consistent with the way many loss functions expect the data.\n",
    "\n",
    "3. Data Structure:\n",
    "   - Raw data: Two separate arrays for inputs and labels\n",
    "   - Wrapped data: List of tuples, each containing an input and its corresponding label\n",
    "   \n",
    "   Reason: This pairing makes it easier to shuffle and batch the data during training.\n",
    "\n",
    "4. Validation and Test Data:\n",
    "   - The wrapper keeps the labels as integers for validation and test data.\n",
    "   \n",
    "   Reason: During validation and testing, we typically want to compare the network's output directly to the true label, so keeping it as an integer is more convenient.\n",
    "\n",
    "The wrapper function prepares the data in a format that's more directly usable for training neural networks. It saves time and reduces the likelihood of errors when implementing the training process.\n",
    "\n",
    "Key benefits of using the wrapped data:\n",
    "1. Consistent input shape for matrix operations\n",
    "2. One-hot encoded labels for training data\n",
    "3. Paired inputs and labels for easy batching\n",
    "4. Properly shaped data that's ready to feed into a neural network\n",
    "\n",
    "This preparation step separates the data handling logic from the neural network implementation, making the overall code cleaner and more modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9809466-22df-43da-8c92-ae8eeddb884d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
